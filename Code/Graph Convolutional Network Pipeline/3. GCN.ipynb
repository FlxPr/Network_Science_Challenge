{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "from dgl.nn.pytorch.conv import SAGEConv, GATConv\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to perform each step of training\n",
    "def train_step(g, features, edges, y, mask):\n",
    "    # Sets model to TRAIN mode\n",
    "    model.train()\n",
    "    # Makes predictions\n",
    "    y_hat = model(g, features, edges)\n",
    "    # Computes loss\n",
    "    y = y.float().view(-1,1)\n",
    "    loss = loss_fn(y_hat[mask], y[mask])\n",
    "    # Computes gradients\n",
    "    loss.backward()\n",
    "    # Updates parameters and zeroes gradients\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # Returns the loss\n",
    "    return loss.item()\n",
    "\n",
    "# A helper function to perform each step of validation\n",
    "def val_step(g, features, edges, y, mask):\n",
    "    # Avoid to compute gradients\n",
    "    with th.no_grad():\n",
    "        # Switch to evaluation mode\n",
    "        model.eval()\n",
    "        # Makes predictions\n",
    "        y_hat = model(g, features, edges)\n",
    "        # Computes loss\n",
    "        y = y.float().view(-1,1)\n",
    "        loss = loss_fn(y_hat[mask], y[mask])\n",
    "        # Returns the loss\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy on the test set\n",
    "def accuracy(model, g, features, edges, y, mask):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "\n",
    "        # Makes predictions\n",
    "        y_hat = model(g, features, edges)\n",
    "        y_hat[y_hat>0.5] = 1\n",
    "        y_hat[y_hat<0.5] = 0\n",
    "            \n",
    "        # Calculate accuracies\n",
    "        y = y.float().view(-1,1)\n",
    "        errors = th.mean(th.abs(y[mask] - y_hat[mask]))\n",
    "            \n",
    "        print('Accuracy:', (1 - errors).item())\n",
    "        \n",
    "# Generate predictions\n",
    "def predict(model, g, features, edges):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "\n",
    "        # Makes predictions\n",
    "        y_hat = model(g, features, edges)\n",
    "        y_hat[y_hat>0.5] = 1\n",
    "        y_hat[y_hat<0.5] = 0\n",
    "        \n",
    "        return y_hat.cpu().squeeze(1).detach().numpy() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('training_set.txt', header=None, sep=' ', names=['X1', 'X2', 'Y'])\n",
    "df_test = pd.read_csv('testing_set.txt', header=None, sep=' ', names=['X1', 'X2'])\n",
    "df_features = pd.read_csv('df_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Re-index IDs to consecutive intergers ranging from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the info dataframe\n",
    "df_features = df_features.reset_index()\n",
    "df_features.rename({'index':'new_id', 'ID':'old_id'}, axis=1, inplace=True)\n",
    "\n",
    "# Keep track of ID mappings\n",
    "old_2_new = df_features.set_index('old_id')[['new_id']].to_dict()['new_id']\n",
    "\n",
    "# Map the training and test data\n",
    "df_train['X1'] = df_train['X1'].map(old_2_new)\n",
    "df_train['X2'] = df_train['X2'].map(old_2_new)\n",
    "df_test['X1'] = df_test['X1'].map(old_2_new)\n",
    "df_test['X2'] = df_test['X2'].map(old_2_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('Y', axis=1)\n",
    "y = df_train['Y']\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Graph Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Construct a graph in DGL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph from networkx\n",
    "edges = X[y==1]\n",
    "nxg = nx.from_pandas_edgelist(edges, 'X1', 'X2', None, create_using=nx.DiGraph())\n",
    "\n",
    "# Put into DGL format\n",
    "G = dgl.DGLGraph().to(device)\n",
    "G.from_networkx(nxg)\n",
    "\n",
    "# Add nodes that don't exist in the existing graph but in the info dataframe\n",
    "G.add_nodes(86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Constrcut node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = X.values\n",
    "edges_test = X_test.values\n",
    "labels = th.IntTensor(y.values).view(-1, 1).to(device)\n",
    "\n",
    "# Normalization\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "features = df_features.fillna(df_features.mode().iloc[0])\n",
    "features = features.values[:, 2:]\n",
    "features = scaler.fit_transform(features)\n",
    "features = th.FloatTensor(features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features: 51\n"
     ]
    }
   ],
   "source": [
    "print('The number of features:', features.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Split training and test links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training data: 492409\n",
      "The size of validation data: 123103\n"
     ]
    }
   ],
   "source": [
    "mask = np.arange(len(edges))\n",
    "np.random.shuffle(mask)\n",
    "mask_train, mask_val = mask[:int(len(mask)*0.8)], mask[int(len(mask)*0.8):]\n",
    "\n",
    "print('The size of training data:', len(mask_train))\n",
    "print('The size of validation data:', len(mask_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling and Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GATConv(51, 300, 5, residual=True, activation=F.relu)\n",
    "        self.gcn2 = GATConv(300, 20, 3, residual=True, activation=F.relu)\n",
    "        self.gcn3 = GATConv(20, 20, 3, residual=True, activation=F.relu)\n",
    "        self.gcn4 = GATConv(20, 10, 2, residual=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(20, 50)\n",
    "        self.fc2 = nn.Linear(50, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, g, features, edges):\n",
    "        \n",
    "        # Learning node embeddings\n",
    "        emb = self.gcn1(g, features)\n",
    "        emb = emb.max(1)[0]\n",
    "        emb = self.gcn2(g, emb)\n",
    "        emb = emb.max(1)[0]\n",
    "        emb = self.gcn3(g, emb)\n",
    "        emb = emb.max(1)[0]\n",
    "        emb = self.gcn4(g, emb)\n",
    "        emb = emb.max(1)[0]        \n",
    "        \n",
    "        # Encode nodes\n",
    "        emb1 = emb[edges[:, 0]]\n",
    "        emb2 = emb[edges[:, 1]]\n",
    "        emb_edges = th.cat([emb1, emb2], axis=1)\n",
    "        \n",
    "        # Classify edges\n",
    "        y = th.relu(self.fc1(emb_edges))\n",
    "        y = th.relu(self.fc2(y))\n",
    "        y = th.relu(self.fc3(y))\n",
    "        y = th.sigmoid(self.fc4(y))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = Net().to(device)\n",
    "\n",
    "# Loss function \n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# The number of epochs\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss: 0.7146669626235962\n",
      "Epoch 0 Validation Loss: 0.7017821073532104\n"
     ]
    }
   ],
   "source": [
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # 1 step of training\n",
    "    loss_train = train_step(G, features, edges, labels, mask_train)\n",
    "    losses_train.append(loss_train)\n",
    "    \n",
    "    # Keep track of validation loss\n",
    "    with th.no_grad():\n",
    "        # 1 step of validation\n",
    "        loss_val = val_step(G, features, edges, labels, mask_val)\n",
    "        losses_val.append(loss_val)\n",
    "    \n",
    "    # Report losses\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch {} Training Loss: {}'.format(epoch, loss_train))\n",
    "        print('Epoch {} Validation Loss: {}'.format(epoch, loss_val))\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), 'models//model_{}'.format(epoch))\n",
    "        \n",
    "        # Save the loss\n",
    "        df_loss = pd.DataFrame({'Training':losses_train, \n",
    "                                'Validation': losses_val})\n",
    "        df_loss.to_csv('losses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Training Phase--\n",
      "Accuracy: 0.8332179188728333\n",
      "--Validation Phase--\n",
      "Accuracy: 0.8324329853057861\n"
     ]
    }
   ],
   "source": [
    "print('--Training Phase--')\n",
    "accuracy(model, G, features, edges, labels, mask_train)\n",
    "print('--Validation Phase--')\n",
    "accuracy(model, G, features, edges, labels, mask_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling on the full data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Define hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = Net().to(device)\n",
    "\n",
    "# Loss function \n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# The number of epochs\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # 1 step of training\n",
    "    loss_train = train_step(G, features, edges, labels, mask)\n",
    "    losses_train.append(loss_train)\n",
    "    \n",
    "    # Report losses\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch {} Training Loss: {}'.format(epoch, loss))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--Training Phase--')\n",
    "accuracy(model, G, features, edges, labels, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(model, G, features, edges_test)\n",
    "df_pred = pd.DataFrame({'id':range(len(pred)),\n",
    "                        'category':pred})\n",
    "df_pred.to_csv('predictions.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
